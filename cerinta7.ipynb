{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 7 Proces de Streaming și Inferență ML în timp real cu PySpark\n",
        "\n",
        "---\n",
        "\n",
        "## Ce am vrut să demonstrăm\n",
        "\n",
        "În această ultimă secțiune, am implementat un **proces simplu de streaming** în PySpark, cu scopul de a simula un flux de date care vine în timp real și de a aplica pe fiecare batch un **model ML deja antrenat**. Concret, ne-am pus în pielea unei aplicații care monitorizează scorul de libertate al țărilor și îl actualizează automat pe măsură ce vin date noi.\n",
        "\n",
        "---\n",
        "\n",
        "## Structura procesului\n",
        "\n",
        "| Componentă         | Descriere                                                                 |\n",
        "| ------------------ | -------------------------------------------------------------------------- |\n",
        "| Sursă date       | Fișiere CSV scrise treptat într-un folder (`stream_input`) din Google Drive |\n",
        "| Model ML         | `PipelineModel` salvat anterior (Logistic Regression)                     |\n",
        "| Proces Streaming | Un `while` loop care verifică la fiecare 5 secunde dacă a apărut un fișier nou |\n",
        "| Inferență        | Modelul este aplicat imediat pe datele noi și returnează predicția `Low / Medium / High` |\n",
        "\n",
        "---\n",
        "\n",
        "## De ce e valoros\n",
        "\n",
        "- **Simulare realistă** – fără `StreamingContext`, dar potrivită pentru Colab/local;\n",
        "- **Aplicare practică** – putem înlocui oricând fișierele cu un stream Kafka real;\n",
        "- **Util pentru scenarii reale** – predicții automate pentru organizații care vor să monitorizeze evoluția libertății în țări instabile.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "s-y6dBDHw2J9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyspark"
      ],
      "metadata": {
        "id": "-QpoHx5gw4fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- 1. IMPORTURI -----------------\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import PipelineModel\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.feature import IndexToString"
      ],
      "metadata": {
        "id": "VkUzHIN-xwtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- 2. START SPARK -----------------\n",
        "spark = SparkSession.builder.appName(\"StreamingFreedomColab\").getOrCreate()"
      ],
      "metadata": {
        "id": "RqC9PJk1xyGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- 3. CĂI ABSOLUTE DIN GOOGLE DRIVE -----------------\n",
        "model_path = \"/content/drive/MyDrive/Master NLP/Anul 1 Semestrul 2/Big Data/Proiect Final/freedom_classifier_pipeline\"\n",
        "input_dir = \"/content/drive/MyDrive/Master NLP/Anul 1 Semestrul 2/Big Data/Proiect Final/stream_input\"\n"
      ],
      "metadata": {
        "id": "8slXSW8YxzNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- 4. ÎNCĂRCĂM MODELUL -----------------\n",
        "print(\"Încărcăm modelul ML salvat...\")\n",
        "loaded_model = PipelineModel.load(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCWMyCIDx1HG",
        "outputId": "5dbe791e-43d3-4bf5-9a5c-4198216ddd73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Încărcăm modelul ML salvat...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- 5. LOOP DE STREAMING SIMULAT -----------------\n",
        "print(\"Streaming pornit. Citim fișiere din:\", input_dir)\n",
        "\n",
        "processed_files = set()\n",
        "start_time = time.time()\n",
        "timeout = 60  # Rulăm streamingul timp de 60 secunde\n",
        "\n",
        "while time.time() - start_time < timeout:\n",
        "    files = [f for f in os.listdir(input_dir) if f.endswith(\".csv\") and f not in processed_files]\n",
        "\n",
        "    for file in files:\n",
        "        file_path = os.path.join(input_dir, file)\n",
        "        print(f\"\\nFișier detectat: {file}\")\n",
        "        try:\n",
        "            # 1. Citește fișierul și transformă-l în Spark DataFrame\n",
        "            df = pd.read_csv(file_path).dropna()\n",
        "            sdf = spark.createDataFrame(df)\n",
        "            sdf = sdf.withColumn(\"year\", col(\"year\").cast(\"int\"))  # conversie dacă e necesar\n",
        "\n",
        "            # 2. Aplică modelul ML salvat\n",
        "            predictions = loaded_model.transform(sdf)\n",
        "\n",
        "            # 3. Decodează predicția în categorii text (Low, Medium, High)\n",
        "            decoder = IndexToString(\n",
        "                inputCol=\"prediction\",\n",
        "                outputCol=\"predicted_category\",\n",
        "                labels=[\"Low\", \"Medium\", \"High\"]\n",
        "            )\n",
        "            final_df = decoder.transform(predictions)\n",
        "\n",
        "            # 4. Afișează rezultatele\n",
        "            results = final_df.select(\"countries\", \"region\", \"predicted_category\").collect()\n",
        "            for r in results:\n",
        "                print(f\"{r['countries']} ({r['region']}): {r['predicted_category']}\")\n",
        "\n",
        "            processed_files.add(file)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Eroare la {file}: {e}\")\n",
        "\n",
        "    time.sleep(5)\n",
        "\n",
        "print(\"\\nStreaming finalizat.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkSRPswDx3No",
        "outputId": "c7e44ece-30c4-4cbd-933d-980a8334d14a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streaming pornit. Citim fișiere din: /content/drive/MyDrive/Master NLP/Anul 1 Semestrul 2/Big Data/Proiect Final/stream_input\n",
            "\n",
            "Fișier detectat: input_auto_1.csv\n",
            "Korea, Rep. (East Asia): Low\n",
            "Moldova (Eastern Europe): Low\n",
            "Morocco (Middle East & North Africa): Medium\n",
            "Georgia (Caucasus & Central Asia): Low\n",
            "Georgia (Caucasus & Central Asia): Low\n",
            "\n",
            "Fișier detectat: input_auto_2.csv\n",
            "Georgia (Caucasus & Central Asia): Low\n",
            "Colombia (Latin America & the Caribbean): Low\n",
            "Slovenia (Eastern Europe): Low\n",
            "Slovenia (Eastern Europe): Low\n",
            "Slovenia (Eastern Europe): Low\n",
            "\n",
            "Fișier detectat: input_auto_3.csv\n",
            "Ethiopia (Sub-Saharan Africa): Medium\n",
            "Kazakhstan (Caucasus & Central Asia): Medium\n",
            "Moldova (Eastern Europe): Low\n",
            "Slovak Republic (Eastern Europe): Low\n",
            "Jamaica (Latin America & the Caribbean): Low\n",
            "\n",
            "Fișier detectat: input_auto_2 (1).csv\n",
            "Georgia (Caucasus & Central Asia): Low\n",
            "Colombia (Latin America & the Caribbean): Low\n",
            "Slovenia (Eastern Europe): Low\n",
            "Slovenia (Eastern Europe): Low\n",
            "Slovenia (Eastern Europe): Low\n",
            "\n",
            "Fișier detectat: input_auto_2 (2).csv\n",
            "Georgia (Caucasus & Central Asia): Low\n",
            "Colombia (Latin America & the Caribbean): Low\n",
            "Slovenia (Eastern Europe): Low\n",
            "Slovenia (Eastern Europe): Low\n",
            "Slovenia (Eastern Europe): Low\n",
            "\n",
            "Streaming finalizat.\n"
          ]
        }
      ]
    }
  ]
}